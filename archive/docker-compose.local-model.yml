version: "3.8"

# DJL with local model files (no internet access required)
# Mount your model directory to /opt/ml/model inside the container

services:
  djl-local:
    image: deepjavalibrary/djl-serving:0.32.0-pytorch-cpu
    ports:
      - "8080:8080"
    volumes:
      # Mount your local model directory
      # Replace ./model with the path to your model directory
      - ./model:/opt/ml/model:ro
    environment:
      # Tell DJL to load from the mounted directory
      - SERVING_LOAD_MODELS=file:///opt/ml/model
      - OMP_NUM_THREADS=4
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '2'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s

  solr9:
    image: solr:9.7
    ports:
      - "8984:8983"
    environment:
      - SOLR_HEAP=2g
    volumes:
      - solr9_data:/var/solr
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8983/solr/admin/info/system || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3

volumes:
  solr9_data:
